# Trimming the ℓ₁ Regularizer: Statistical Analysis, Optimization, and Applications to Deep Learning
+ Jihun Yun (KAIST), Peng Zheng (University of Washington), Eunho Yang (KAIST, AITRICS), Aurélie C. Lozano (IBM T.J.
Watson Research Center), and Aleksandr Aravkin (University of Washington)

This repo contains implementations for our **ICML 2019** paper "Trimming the ℓ₁ Regularizer: Statistical Analysis, Optimization, and Applications to Deep Learning".

## Trimmed ℓ₁ Penalty
Trimmed ℓ₁ penalty leaves $h$ largest entries unpenalized.
